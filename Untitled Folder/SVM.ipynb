{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正確: [3. 2. 2. 3. 1. 1. 3. 3. 1. 1. 2. 1. 2. 1. 1. 2. 1. 1. 2. 3. 3. 3. 1. 3.\n",
      " 1. 1. 3. 3. 3. 1. 2. 2. 1. 2. 1. 3. 2. 1. 2. 1. 1. 3. 1. 2. 3. 2. 2. 2.\n",
      " 1. 2. 3. 1. 2. 2. 1. 3. 3. 3.]\n",
      "------------------------------------------------------------\n",
      "預測: [3. 2. 2. 3. 1. 1. 3. 3. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 2. 3. 3. 3. 1. 3.\n",
      " 1. 2. 3. 3. 3. 1. 2. 2. 2. 2. 1. 3. 2. 1. 2. 1. 1. 3. 1. 3. 3. 1. 2. 2.\n",
      " 1. 2. 1. 1. 2. 2. 1. 3. 3. 3.]\n",
      "------------------------------------------------------------\n",
      "比對: [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True False  True False  True  True\n",
      "  True  True False  True  True  True  True  True  True  True]\n",
      "------------------------------------------------------------\n",
      "正確率: 0.9\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "\n",
    "#--------------------------------\n",
    "# 匯入外部模組\n",
    "#--------------------------------\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------\n",
    "# SBS\n",
    "#-------------------------------------------------\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=self.test_size,\n",
    "                             random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train,\n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train,\n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------\n",
    "#-------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "#-------------------------------------------------\n",
    "# read\n",
    "#-------------------------------------------------\n",
    "data=np.genfromtxt('data.csv', delimiter=',')\n",
    "\n",
    "#---------------------------\n",
    "# rand\n",
    "#---------------------------\n",
    "np.random.shuffle(data)\n",
    "\n",
    "#***************************\n",
    "# set\n",
    "#***************************\n",
    "tn=120\n",
    "features=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "label=0\n",
    "\n",
    "#---------------------------\n",
    "# train about 0.7\n",
    "#---------------------------\n",
    "training_data  = data[:tn, features]\n",
    "training_label = data[:tn, label]\n",
    "\n",
    "#---------------------------\n",
    "# test about 0.3\n",
    "#---------------------------\n",
    "testing_data  = data[tn:, features]\n",
    "testing_label = data[tn:, label]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "#***********************************************\n",
    "# 分類\n",
    "#***********************************************\n",
    "svm_rbf = svm.LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
    "     verbose=0)\n",
    "svm_rbf.fit(training_data, training_label)\n",
    "\n",
    "#---------------------------\n",
    "# 分類測試\n",
    "#---------------------------\n",
    "print('正確:', testing_label)\n",
    "print('-'*60)\n",
    "\n",
    "predict = svm_rbf.predict(testing_data)\n",
    "print('預測:', predict)\n",
    "print('-'*60)\n",
    "\n",
    "#---------------------------\n",
    "# 和正確資料比對\n",
    "#---------------------------\n",
    "results = testing_label == predict\n",
    "print('比對:', results)\n",
    "print('-'*60)\n",
    "\n",
    "#---------------------------\n",
    "# 正確率\n",
    "#---------------------------\n",
    "print('正確率:', round(np.sum(results)/len(results), 2))\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "#---------------------------\n",
    "# printf\n",
    "#---------------------------\n",
    "\n",
    "\n",
    "\n",
    "#C=1.0 \n",
    "#邊界寬度\n",
    "\n",
    "#models=(svm.SVC(kernel='linear',C=C),\n",
    "#       svm.LinearSVC(C=C),\n",
    "#       svm.SVC(kernel='rbf',gamma=0.7,C=C),\n",
    "#       svm.SVC(kernel='poly',degree=5,C=C))\n",
    "#\n",
    "#models=(clf.fit(x,y) for clf in models)\n",
    "#titles=(\"SVC with linear kernel\",\n",
    "#       \"LinearSVC (linear kernel)\",\n",
    "#       \"SVC with RBF kernel\",\n",
    "#       \"SVC with polynomial(degree5) kernel\")\n",
    "#fig,sub=plt.subplots(2,2)\n",
    "#\n",
    "#plt.subplots_adjust(wspace=0.4,hspace=0.4)\n",
    "#X0,X1=training_data[:,0],training_data[:,1]\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#xx,yy=make_meshgrid(X0,X1)\n",
    "#\n",
    "#for clf,titles,ax in zip(models,titles,sub.flatten()):\n",
    "#    plot_cintours(ax,clf,xx,yy,cmap=plt.cm.coolwarm ,plpha=0.8)\n",
    "#    \n",
    "#    ax.scatter(X0,X1,c=y,cmap=plt.cm.coolwarm,s=20,edgecolors='k')\n",
    "#    ax.set_xlim(xx.min(),xx.max())\n",
    "#    ax.set_ylim(yy.min(),yy.max())\n",
    "#    ax.set_xlabel(\"Sepal length\")\n",
    "#    ax.set_ylabel(\"Sepal width\")\n",
    "#    ax.set_xticks(())\n",
    "#    ax.set_yticks(())\n",
    "#    ax.set_title(titles)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
